### 项目介绍

#### 项目简介
北京交通大学软件2024小学期项目，算法段，本项目旨在实现一个综合的智能视频分析系统，具备多种人脸和行为识别功能。通过多种算法的集成，项目能够实现人脸采集、姿态识别、情感检测、摔倒检测、火灾检测等多种应用，适用于智能安防、义工服务等多个领域。
使用grpc与后端交互。
#### 功能模块
1. **人脸采集与检测**
   - **姿态识别模型**：使用Hopenet模型进行姿态估计，通过估计yaw角度判断人脸方向，当人脸保持正面超过2秒且图像质量最高时完成截图。
   - **人脸检测模型**：使用dlib库进行人脸检测，截取人脸并保存到本地已知人脸文件夹。
   - **图像特征点识别**：利用dlib进行人脸特征点检测，通过拉普拉斯变换方差评估图像清晰度。

2. **进出入人脸识别**
   - **人脸识别模型**：识别人脸并与数据库中的已知人脸进行匹配，判断进出入人员的身份。

3. **情感检测**
   - **情绪检测模型**：识别人脸表情，分析情感状态。

4. **义工交互**
   - **人脸识别**：识别义工身份。
   - **距离检测算法**：检测义工与被服务对象的距离。
   - **情绪检测模型**：识别被服务对象的情绪状态，提供更好的服务体验。

5. **陌生人追踪**
   - **目标追踪**：实时追踪陌生人移动路径。
   - **步态识别**：通过步态分析识别陌生人。
   - **图像分割与目标检测**：精确分割并检测目标。

6. **摔倒检测**
   - **摔倒识别模型**：识别并检测人员摔倒事件。
   - **目标检测**：确保目标检测的准确性。

7. **火灾检测**
   - **目标检测**：检测火灾相关目标，如烟雾和火焰。

8. **入侵检测**
   - **目标追踪**：实时追踪入侵者。
   - **目标检测**：检测入侵目标，发出警报。

#### 数据采集与处理流程
1. **前端数据采集**
   - 开启采集功能并发送用户信息，拉取指定视频流。
   - 使用Hopenet模型进行姿态估计，根据yaw角度判断人脸方向。
   - 保持正面时保存帧并调用FQA算法评估图像质量，若持续2秒正面且最优人脸特征点超过1000，则完成截图并返回截取成功，否则持续进行直到前端关闭此进程。

2. **图像处理与分析**
   - 使用dlib进行人脸特征点检测，并计算特征点的拉普拉斯变换方差来评估图像清晰度。
   - 使用dlib库中的人脸检测器截取人脸并保存到本地已知人脸文件夹，根据收到的用户信息命名，并上传到OSS（对象存储服务），返回成功信息和OSS存储的URL。

#### 项目架构
该项目基于多种先进的算法和模型，整合了人脸检测、人脸识别、姿态估计、情感分析等功能模块，旨在提供全面的智能视频分析解决方案。项目的前端负责数据采集和基本处理，后端进行复杂的分析和识别任务，并将结果返回前端。

#### 技术栈
- **前端**：JavaScript, HTML, CSS
- **后端**：Python, Flask/Django
- **算法库**：dlib, Hopenet
- **存储**：OSS（对象存储服务）

#### 开发者
【BJTU】20+躺平养老院
